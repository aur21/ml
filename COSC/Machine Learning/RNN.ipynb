{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "express-depth",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks: Programming Practice\n",
    "\n",
    "COSC 410: Applied Machine Learning\\\n",
    "Colgate University\\\n",
    "*Prof. Apthorpe*\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook will give you practice with the following topics:\n",
    "  1. Creating and training simple RNNs\n",
    "  2. Creating and training LSTM & GRU networks\n",
    "\n",
    "We will be using a new **natural language** dataset of IMDB movie reviews. We will attempt to perform a classification task to label reviews as having either *positive* or *negative* sentiment. The reviews have already been preprocessed from words --> numbers, such that the most common word is encoded as 1, the second most common word is encoded as 2, etc. \n",
    "\n",
    "## Part 1. Data Import & Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "infectious-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "empirical-possibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 1s 0us/step\n",
      "17473536/17464789 [==============================] - 1s 0us/step\n",
      "25000 Training sequences\n",
      "25000 Validation sequences\n",
      "[12500 12500]\n",
      "[12500 12500]\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000  # Only consider the top 20k words\n",
    "maxlen = 200  # Only consider the first 200 words of each movie review\n",
    "\n",
    "(x_train, y_train), (x_val, y_val) = ks.datasets.imdb.load_data(num_words=max_features) # Load the dataset\n",
    "\n",
    "x_train = ks.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen) # Pad reviews with 0s to equal length\n",
    "x_val = ks.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen) # Pad reviews with 0s to equal length\n",
    "\n",
    "print(len(x_train), \"Training sequences\") # Print number of training reviews\n",
    "print(len(x_val), \"Validation sequences\") # Print number of validation reviews\n",
    "\n",
    "print(np.unique(y_train, return_counts=True)[1]) # print counts of classes in training set\n",
    "print(np.unique(y_val, return_counts=True)[1]) # print counts of classes in validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-valve",
   "metadata": {},
   "source": [
    "**Note:** One of the benefits of RNNs is that they can handle sequences of differing lengths, so why do we pad the training and validation data to equal lengths? ... Training time! Keras is optimized for mini-batch gradient descent when the training examples are non-ragged matrices (a.k.a. *tensors*...hence \"Tensorflow\"). Once we have trained the model, we can perform predictions on *new* reviews of arbitary length.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "automotive-france",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "1654784/1641221 [==============================] - 0s 0us/step\n",
      "to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n",
      "\n",
      "Label: 0\n",
      "           the thought solid thought senator do making to is spot nomination assumed while he of jack in where picked as getting on was did hands fact characters to always life thrillers not as me can't in at are br of sure your way of little it strongly random to view of love it so principles of guy it used producer of where it of here icon film of outside to don't all unique some like of direction it if out her imagination below keep of queen he diverse to makes this stretch stefan of solid it thought begins br senator machinations budget worthwhile though ok brokedown awaiting for ever better were and diverse for budget look kicked any to of making it out and follows for effects show to show cast this family us scenes more it severe making senator to and finds tv tend to of emerged these thing wants but and an beckinsale cult as it is video do you david see scenery it in few those are of ship for with of wild to one is very work dark they don't do dvd with those them\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function that converts an embedded review back into English bag-of-words representation\n",
    "def reverse_embedding(review):\n",
    "    words_to_ints = ks.datasets.imdb.get_word_index(path=\"imdb_word_index.json\")\n",
    "    reverse_embedding_map = dict(zip(words_to_ints.values(), words_to_ints.keys()))\n",
    "    return \" \".join([reverse_embedding_map.get(x, \"\") for x in review])\n",
    "\n",
    "# Function that prints the label (1 = positive review, 0 = negative review) and bag-of-words text of a review\n",
    "def print_example_and_label(idx):\n",
    "    print(f\"Label: {y_train[idx]}\")\n",
    "    print(reverse_embedding(x_train[idx]) + \"\\n\")\n",
    "    \n",
    "print_example_and_label(0)\n",
    "print_example_and_label(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-logan",
   "metadata": {},
   "source": [
    "## Part 2. 1-Node RNNs\n",
    "\n",
    "We'll start by creating three different 1-Node RNNs with `SimpleRNN`, `LSTM`, and `GRU` nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "quantitative-strap",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 0.6938 - accuracy: 0.5366 - val_loss: 0.6735 - val_accuracy: 0.5992\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.6531 - accuracy: 0.6426 - val_loss: 0.6509 - val_accuracy: 0.6142\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.6199 - accuracy: 0.6817 - val_loss: 0.6369 - val_accuracy: 0.6249\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.5916 - accuracy: 0.7094 - val_loss: 0.6303 - val_accuracy: 0.6368\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.5673 - accuracy: 0.7299 - val_loss: 0.6284 - val_accuracy: 0.6424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f2a9f900d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SimpleRNN model\n",
    "model = ks.Sequential([\n",
    "    ks.Input(shape=(None,)),\n",
    "    ks.layers.Embedding(max_features, 1),\n",
    "    ks.layers.SimpleRNN(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "least-alarm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 35s 43ms/step - loss: 0.6869 - accuracy: 0.5718 - val_loss: 0.6654 - val_accuracy: 0.6524\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.6352 - accuracy: 0.6806 - val_loss: 0.6208 - val_accuracy: 0.6670\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 26s 34ms/step - loss: 0.5855 - accuracy: 0.7215 - val_loss: 0.5925 - val_accuracy: 0.6855\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 27s 34ms/step - loss: 0.5460 - accuracy: 0.7518 - val_loss: 0.5724 - val_accuracy: 0.7073\n",
      "Epoch 5/5\n",
      "638/782 [=======================>......] - ETA: 4s - loss: 0.5128 - accuracy: 0.7759"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Python310\\RuntimeEnv\\venv-COSC410\\Machine Learning\\RNN.ipynb Cell 8'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Python310/RuntimeEnv/venv-COSC410/Machine%20Learning/RNN.ipynb#ch0000007?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m ks\u001b[39m.\u001b[39mSequential([\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Python310/RuntimeEnv/venv-COSC410/Machine%20Learning/RNN.ipynb#ch0000007?line=2'>3</a>\u001b[0m     ks\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(\u001b[39mNone\u001b[39;00m,)),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Python310/RuntimeEnv/venv-COSC410/Machine%20Learning/RNN.ipynb#ch0000007?line=3'>4</a>\u001b[0m     ks\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mEmbedding(max_features, \u001b[39m1\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Python310/RuntimeEnv/venv-COSC410/Machine%20Learning/RNN.ipynb#ch0000007?line=4'>5</a>\u001b[0m     ks\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mLSTM(\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Python310/RuntimeEnv/venv-COSC410/Machine%20Learning/RNN.ipynb#ch0000007?line=5'>6</a>\u001b[0m ])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Python310/RuntimeEnv/venv-COSC410/Machine%20Learning/RNN.ipynb#ch0000007?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Python310/RuntimeEnv/venv-COSC410/Machine%20Learning/RNN.ipynb#ch0000007?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(x_val, y_val))\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> <a href='file:///c%3A/Python310/lib/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LSTM model\n",
    "model = ks.Sequential([\n",
    "    ks.Input(shape=(None,)),\n",
    "    ks.layers.Embedding(max_features, 1),\n",
    "    ks.layers.LSTM(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "promising-greensboro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 39s 47ms/step - loss: 0.6847 - accuracy: 0.5674 - val_loss: 0.6720 - val_accuracy: 0.6149\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 36s 46ms/step - loss: 0.6494 - accuracy: 0.6570 - val_loss: 0.6423 - val_accuracy: 0.6276\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.6094 - accuracy: 0.6967 - val_loss: 0.6199 - val_accuracy: 0.6409\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 52s 67ms/step - loss: 0.5744 - accuracy: 0.7185 - val_loss: 0.6063 - val_accuracy: 0.6516\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 53s 67ms/step - loss: 0.5451 - accuracy: 0.7371 - val_loss: 0.5985 - val_accuracy: 0.6660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f2a68145b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU model\n",
    "model = ks.Sequential([\n",
    "    ks.Input(shape=(None,)),\n",
    "    ks.layers.Embedding(max_features, 1),\n",
    "    ks.layers.GRU(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-affiliation",
   "metadata": {},
   "source": [
    "## Part 3. Recurrent Layer Hyperparameters\n",
    "\n",
    "`SimpleRNN`, `LSTM` and `GRU` layers share several hyperparameters that can be set via keyword arguments. The documentation for each of these layers is here: https://keras.io/api/layers/recurrent_layers/\n",
    "  * `return_sequences`: Whether the layers should return a single value for each input sequence (`False`, *default*) or a new multi-step sequence for each input sequence (`True`)\n",
    "  * `kernel_regularizer`, `bias_regularizer`, and `recurrent_regularizer` for L1, L2, or L1L2 regularization\n",
    "  * `dropout` and `recurrent_dropout` for setting dropout rates of forward and recurrent connections. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-reynolds",
   "metadata": {},
   "source": [
    "## Part 4: Stacked RNNs\n",
    "\n",
    "Finally, let's try a stacked LSTM network with 2 hidden layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked LSTM model\n",
    "model = ks.Sequential([\n",
    "    ks.Input(shape=(None,)),\n",
    "    ks.layers.Embedding(max_features, 1),\n",
    "    ks.layers.LSTM(64, return_sequences=True)\n",
    "    ks.layers.LSTM(64, return_sequences=True)\n",
    "    ks.layers.LSTM(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-japanese",
   "metadata": {},
   "source": [
    "We can see that the stacked RNN has higher plateau performance and reaches that performance more quickly. However, the increasing difference between train accuracy and val accuracy indicates that we are in an overfitting regime, so it doesn't make sense to increase the size of the network further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-honduras",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
