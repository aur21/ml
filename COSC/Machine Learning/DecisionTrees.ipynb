{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ranging-crack",
   "metadata": {},
   "source": [
    "# Decision Trees: Programming Practice\n",
    "\n",
    "COSC 410: Applied Machine Learning\\\n",
    "Colgate University\\\n",
    "*Prof. Apthorpe*\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook will give you practice with the following topics:\n",
    "  1. Training decision tree models for classification\n",
    "  2. Visualizing decision trees and decision tree performance\n",
    "  3. Using decision trees to measure feature importance\n",
    "  \n",
    "We will be using a combination of available datasets from the American Community Survey (ACS) and the Federal Communications Commission (FCC).  The goal will be to understand the nature of broadband deployment across the city of Chicago, specifically what geographic and demographic features turn out to be good predictors of broadband deployment. This question is particularly relevant in the new \"Zoom era,\" as access to high-speed Internet connections can determine access to education, jobs, and social support. \n",
    "\n",
    "The existence of broadband connectivity in a certain area can be measured in a variety of ways (e.g., available speed tiers, subscriptions, measured performance) and reported in different ways (e.g., by ISPs or by citizens/subscribers). We will use data reported by ISPs, who are required to report their service offerings by Census block to the FCC yearly. \n",
    "\n",
    "**NOTE:** You will need run the following pip install commands, and then restart jupyter-lab for this notebook to work: \n",
    "* `pip install sodapy`\n",
    "* `pip install geopandas`\n",
    "* `pip install descartes`\n",
    "* `pip install censusdata`\n",
    "* `pip install pydotplus`\n",
    "\n",
    "You MAY also need to install [Graphviz](https://graphviz.org/), but you should try the notebook without it first.\n",
    "\n",
    "This notebook is adapted from the University of Chicago's Machine Learning for Public Policy course.\n",
    "\n",
    "\n",
    "## Part 1. Data Import & Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-intellectual",
   "metadata": {},
   "source": [
    "#### FCC Broadband Map Data\n",
    "\n",
    "Given that the broadband data reported to the FCC is a large dataset, we will work with a truncated version specifically for Chicago. The FCC makes this data available for exploration on its [website]!(https://broadbandmap.fcc.gov/) and [for download](https://broadbandmap.fcc.gov/#/data-download). The specific data that we will use today is from June 2019 in Cook County, IL. The following code downloads the data according to the API documentation. The download should take no more than 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-migration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sodapy import Socrata\n",
    "\n",
    "client = Socrata(\"opendata.fcc.gov\", None)\n",
    "\n",
    "# Census blockcode is the only geographic attribute, so we limit the data to Cook County \n",
    "# Returned as JSON from API and converted to Python list of dictionaries by sodapy \n",
    "results = client.get(\"c67e-jknh\", limit=800000, where=\"starts_with(blockcode, '17031')\")\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "fcc_df = pd.DataFrame.from_records(results)\n",
    "\n",
    "# Sanity check shape and first 2 rows\n",
    "print(fcc_df.shape)\n",
    "fcc_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-russian",
   "metadata": {},
   "source": [
    "We should explore this data with visualizations before diving into the machine learning. Specifically, we will produce the following three maps for the City of Chicago:\n",
    "1. The maximum contractual downstream speed offered by any provider in each Census block group.\n",
    "2. The number of unique ISPs that offer service in each Census block group.\n",
    "3. The number of unique ISPs that offer service at or above 25 Mbps downstream and 3 Mbps upstream in each Census block group. (This is the FCC's definition of broadband Internet access).\n",
    "\n",
    "We will do this by joining the Census Block code in each row of our processed FCC data with the City of Chicago's geographic data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-defeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recast up/down speed data from text to numeric\n",
    "fcc_df['maxcirdown'] = fcc_df['maxcirdown'].astype(float)\n",
    "fcc_df['maxcirup'] = fcc_df['maxcirup'].astype(float)\n",
    "\n",
    "# Get 12-digit block group FIPS code\n",
    "fcc_df['block_group_id'] = fcc_df['blockcode'].str.slice(0, 12)\n",
    "\n",
    "# Aggregate data to answer questions\n",
    "max_speed_by_blockgroup = fcc_df.groupby('block_group_id').agg({'maxcirdown': 'max'}).rename(columns={'maxcirdown': 'max_speed'})\n",
    "num_isp_by_blockgroup = fcc_df.groupby('block_group_id').agg({'provider_id': pd.Series.nunique}).rename(columns={'provider_id': 'num_isp'})\n",
    "num_broadband_by_blockgroup = fcc_df[(fcc_df['maxcirdown'] >= 25) & (fcc_df['maxcirup'] >= 3)].groupby('block_group_id').agg({'provider_id': pd.Series.nunique}).rename(columns={'provider_id': 'num_broadband'})\n",
    "\n",
    "# Join aggregated data into one dataframe\n",
    "data_by_blockgroup = max_speed_by_blockgroup.join([num_isp_by_blockgroup, num_broadband_by_blockgroup])\n",
    "\n",
    "# Replace NaNs with 0 and convert counts to ints\n",
    "data_by_blockgroup = data_by_blockgroup.fillna(value={'num_broadband': 0}).reset_index()\n",
    "data_by_blockgroup['num_broadband'] = data_by_blockgroup['num_broadband'].astype(int)\n",
    "\n",
    "# Load census block boundaries geojson\n",
    "client = Socrata(\"data.cityofchicago.org\", None)\n",
    "results = client.get(\"bt9m-d2mf\", content_type=\"geojson\", limit=50000)\n",
    "\n",
    "# Convert to pandas DataFrame and aggregate maps at the block group level\n",
    "blocks = gpd.GeoDataFrame.from_features(results)\n",
    "blocks['block_group_id'] = blocks['geoid10'].str.slice(0, 12)\n",
    "blockgroups = blocks.dissolve(by='block_group_id')\n",
    "\n",
    "# Join onto boundary df\n",
    "fcc_map = blockgroups.merge(data_by_blockgroup, how='left', on='block_group_id').set_index('block_group_id')\n",
    "\n",
    "print(fcc_map.shape)\n",
    "fcc_map.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT: Maximum advertised downstream speed offered by any provider \n",
    "map1 = fcc_map.plot(column='max_speed', cmap=\"Blues\", edgecolor=\"0.5\", linewidth= 0.1, figsize=(10, 7), legend=True)\n",
    "map1.set_title(\"Maximum contractually obligated downstream speed by block\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT: The number of unique ISPs that offer service \n",
    "map2 = fcc_map.plot(column='num_isp', cmap=\"Blues\", edgecolor=\"0.5\", linewidth= 0.1, figsize=(10, 7), legend=True)\n",
    "map2.set_title(\"Number of unique ISPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT: Number of unique ISPs that offer service 25+ Mbps downstream and 3+ Mbps upstream \n",
    "map3 = fcc_map.plot(column='num_broadband', cmap=\"Blues\", edgecolor=\"0.5\", linewidth= 0.1, figsize=(10, 7), legend=True)\n",
    "map3.set_title(\"Number of unique ISPs with broadband service\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-indian",
   "metadata": {},
   "source": [
    "#### ACS Data\n",
    "\n",
    "The American Community Survey (ACS) provides data on broadband Internet access subscriptions, as reported by participants. For this lab, we will use the ACS 5-year estimates at the Census block group level for 2018.\n",
    "\n",
    "The following cell uses the Census API to perform the following for block groups in the City of Chicago:\n",
    "\n",
    "1. Load ACS data for percentages of broadband Internet access of any type\n",
    "2. Load ACS data for Total Population, number of white residents, number of Black residents, and median income â€“ and then compute the following:\n",
    "   * the percentage of each Census block's population that is white and Black\n",
    "   * the median income for the block\n",
    "   * the population density of the block (e.g. in units of population per square kilometer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "import censusdata\n",
    "\n",
    "# Pull ACS data \n",
    "census_tables = {\n",
    "    'GEO_ID': 'GEO_ID', \n",
    "    'B28011_001E': 'Internet Total', \n",
    "    'B28011_004E': 'Broadband', \n",
    "    'B02001_001E': 'Race Total', \n",
    "    'B02001_002E': 'White', \n",
    "    'B02001_003E': 'Black', \n",
    "    'B19013_001E': 'Median Income'}\n",
    "acs_df = censusdata.download(\"acs5\", 2018, censusdata.censusgeo([(\"state\", \"17\"), (\"county\", \"031\"), (\"tract\", \"*\"), (\"block group\", \"*\")]), list(census_tables.keys()))\n",
    "acs_df.rename(columns=census_tables, inplace=True)\n",
    "\n",
    "# Create percentage variables \n",
    "acs_df['pct_broadband_customer_reported'] = acs_df['Broadband'] / acs_df['Internet Total']\n",
    "acs_df['pct_white'] = acs_df['White'] / acs_df['Race Total']\n",
    "acs_df['pct_black'] = acs_df['Black'] / acs_df['Race Total']\n",
    "\n",
    "# Population density is not directly available in ACS - must calculate manually\n",
    "# Units are in people per square kilometer\n",
    "blockgroups.crs = \"EPSG:4326\"\n",
    "blockgroups['area'] = blockgroups.to_crs({'init': 'epsg:3857'}).area / (10**6)\n",
    "acs_df['block_group_id'] = acs_df['GEO_ID'].str.slice(9, 21)\n",
    "acs_df = acs_df.set_index('block_group_id').join(blockgroups['area'], how='right')\n",
    "acs_df['pop_density'] = acs_df['Race Total'] / acs_df['area']\n",
    "\n",
    "acs_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-explosion",
   "metadata": {},
   "source": [
    "## Part 2: Decision Tree Prediction\n",
    "\n",
    "We will next attempt to train a decision tree prediction model to predict ISP-reported broadband Internet access from ACS data (at the Census block level)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-highway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-possible",
   "metadata": {},
   "source": [
    "First we will merge the ACS data with the FCC data and split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge census and broadband data \n",
    "merged_df = acs_df[['Median Income', 'pct_broadband_customer_reported', 'pct_white', 'pct_black', 'pop_density']].join(fcc_map[['max_speed', 'num_isp', 'num_broadband']], how='right').rename(columns={'Median Income': 'median_income'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4828aab1-5c5c-4a67-ac67-65a1c45467e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into 80%/20% train/test sets\n",
    "train_df, test_df = train_test_split(merged_df, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-permission",
   "metadata": {},
   "source": [
    "Next, we will clean-up missing or invalid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean missing income values \n",
    "train_df[\"median_income\"].replace({-666666666.0: np.NAN}, inplace=True)\n",
    "test_df[\"median_income\"].replace({-666666666.0: np.NAN}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca7a36e-dfb9-41b8-a3ec-5d00991759cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute NAs with column means \n",
    "train_means = train_df.mean()\n",
    "train_df = train_df.fillna(train_means)\n",
    "test_df = test_df.fillna(train_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-crash",
   "metadata": {},
   "source": [
    "Then we separate out the labels from the features, converting the labels into binary (has broadband or no broadband)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e8a34-5282-488a-b147-a205631edbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# has_broadband\n",
    "train_df['has_broadband'] = train_df['num_broadband'].apply(lambda x: 1 if x >= 1 else 0)\n",
    "test_df['has_broadband'] = test_df['num_broadband'].apply(lambda x: 1 if x >= 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate labels from targets\n",
    "train_x = train_df[['median_income', 'pct_broadband_customer_reported', 'pct_white', 'pct_black', 'pop_density', 'num_isp']]\n",
    "train_y = train_df['has_broadband']\n",
    "\n",
    "test_x = test_df[['median_income', 'pct_broadband_customer_reported', 'pct_white', 'pct_black', 'pop_density', 'num_isp']]\n",
    "test_y = test_df['has_broadband']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-norfolk",
   "metadata": {},
   "source": [
    "Last class, we manually programmed a *grid search* to optimize model parameters. This time, we will use Scikit-Learn's built-in `GridSearchCV` class to do this automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation folds\n",
    "k = 10\n",
    "\n",
    "# Hyperparameters to tune:\n",
    "params = {\n",
    "    'criterion': {'gini', 'entropy'},\n",
    "    'max_depth': {5, 10, 20},\n",
    "    'min_samples_split': (2,5,10)\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV object with decision tree classifier and hyperparameters\n",
    "grid_tree = GridSearchCV(estimator = DecisionTreeClassifier(random_state=0), param_grid=params, cv=k, return_train_score=True, scoring=['accuracy', 'precision', 'recall'], refit='accuracy')\n",
    "\n",
    "# Train and cross-validate, print results\n",
    "grid_tree.fit(train_x, train_y)\n",
    "grid_tree_result = pd.DataFrame(grid_tree.dv.results_).sort_values(by=['mean_test_accuracy'], ascending=False)\n",
    "grid_tree_result[['param_criterion', 'param_max_depth', 'param_min_samples_split', 'mean_test_accuracy']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-blocking",
   "metadata": {},
   "source": [
    "**DISCUSSION:** What are the optimal values of the hyperparameters? What might the `param_max_depth` values tell us about overfitting?\n",
    "\n",
    "This means that we are able to predict broadband access with an **~79% cross-validation accuracy** (not test set accuracy) from the ACS demographic information. This may not seem great, but a high classification accuracy wasn't the primary goal of this exercise. Instead, we want to know  which features turn out ot be most predictive of broadband access to gain a better understanding of Chicago socioeconomics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-click",
   "metadata": {},
   "source": [
    "## Part 3. Interpreting Decision Trees\n",
    "\n",
    "One way to interpret a decision tree is to just print the tree and see what features are used to divide up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display the tree with the highest test accuracy\n",
    "best_tree = grid_tree.best_estimator_\n",
    "plt.figure(figsize=(24,4), dpi=450)\n",
    "tree.plot_tree(best_tree, filled = True, feature_names = train_x.columns.values, fontsize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-consumer",
   "metadata": {},
   "source": [
    "**DISCUSSION:** What does this tell us about broadband access?\n",
    "\n",
    "We can also view the Gini feature importances that were automatically computed by the tree model when it was trained. This will tell us what was the most important feature that yielded the highest accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create series of features sorted by importance\n",
    "pd.Series(best_tree.feature_importances_, train_x.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-while",
   "metadata": {},
   "source": [
    "**DISCUSSION:** This short list of numbers gives us a LOT to unpack. What are some things that this tells us about broadband access (as reported by ISPs)?\n",
    "\n",
    "We can also plot a confusion matrix on the test set to see how the model is making mistakes. Remeber that the `1` class corresponds to \"has broadband\" and the `0` class corresponds to \"No broadband\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Plot the confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-section",
   "metadata": {},
   "source": [
    "**DISCUSSION:** What does this tell us about broadband access?\n",
    "\n",
    "Finally, we can print and plot the precision/recall for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, PrecisionRecallDisplay\n",
    "\n",
    "# Test set predictions\n",
    "\n",
    "\n",
    "# Print precision/recall/F1 on test set\n",
    "\n",
    "\n",
    "# Display precision/recall curve\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
