{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chronic-applicant",
   "metadata": {},
   "source": [
    "# Regression & K-Nearest Neighbors: Programming Practice\n",
    "\n",
    "COSC 410: Applied Machine Learning\\\n",
    "Colgate University\\\n",
    "*Prof. Apthorpe*\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook will give you practice with the following topics:\n",
    "  * Training linear regression models using gradient descent\n",
    "  * Plotting learning curves to measure overfitting\n",
    "  * Training KNN models and using KNN to provide interpretable ML\n",
    "  \n",
    "We will be using a dataset published by the University of Mons in Belgium with the energy use by household appliances in a research subject's home along with the local weather conditions. We will be attempting to use this data to train a model that can predict energy use given weather conditions alone. This type of prediction could be useful for energy companies to make automatic decisions about managing the power supply or for climate researchers interested in modeling future carbon use based on posible weather patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "working-popularity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import sklearn.linear_model\n",
    "import sklearn.neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-split",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In the cell below, import the `energydata.csv` dataset. Go to the UCI Machine Learning Repository website where this dataset is hosted to read about each of the features: https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "qualified-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pandas read_csv function to import energydata.csv\n",
    "energy = pd.read_csv(\"energydata.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b3125fb-b2f7-4e38-835f-e49fa7f60a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19735, 25)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the shape (# rows, # columns) of the dataset\n",
    "energy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "006c01df-5e01-4533-b94c-c4530f589e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Appliances</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH_1</th>\n",
       "      <th>T2</th>\n",
       "      <th>RH_2</th>\n",
       "      <th>T3</th>\n",
       "      <th>RH_3</th>\n",
       "      <th>T4</th>\n",
       "      <th>RH_4</th>\n",
       "      <th>T5</th>\n",
       "      <th>...</th>\n",
       "      <th>T8</th>\n",
       "      <th>RH_8</th>\n",
       "      <th>T9</th>\n",
       "      <th>RH_9</th>\n",
       "      <th>T_out</th>\n",
       "      <th>Press_mm_hg</th>\n",
       "      <th>RH_out</th>\n",
       "      <th>Windspeed</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Tdewpoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>19.89</td>\n",
       "      <td>47.596667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.730000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.566667</td>\n",
       "      <td>17.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>18.2</td>\n",
       "      <td>48.900000</td>\n",
       "      <td>17.033333</td>\n",
       "      <td>45.53</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>733.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.693333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.722500</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.992500</td>\n",
       "      <td>17.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>18.2</td>\n",
       "      <td>48.863333</td>\n",
       "      <td>17.066667</td>\n",
       "      <td>45.56</td>\n",
       "      <td>6.483333</td>\n",
       "      <td>733.6</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>59.166667</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.626667</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.933333</td>\n",
       "      <td>18.926667</td>\n",
       "      <td>45.890000</td>\n",
       "      <td>17.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>18.2</td>\n",
       "      <td>48.730000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.50</td>\n",
       "      <td>6.366667</td>\n",
       "      <td>733.7</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.066667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.590000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.723333</td>\n",
       "      <td>17.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>18.1</td>\n",
       "      <td>48.590000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.40</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>733.8</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.530000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.530000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.1</td>\n",
       "      <td>48.590000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.40</td>\n",
       "      <td>6.133333</td>\n",
       "      <td>733.9</td>\n",
       "      <td>92.0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Appliances     T1       RH_1    T2       RH_2     T3       RH_3         T4  \\\n",
       "0          60  19.89  47.596667  19.2  44.790000  19.79  44.730000  19.000000   \n",
       "1          60  19.89  46.693333  19.2  44.722500  19.79  44.790000  19.000000   \n",
       "2          50  19.89  46.300000  19.2  44.626667  19.79  44.933333  18.926667   \n",
       "3          50  19.89  46.066667  19.2  44.590000  19.79  45.000000  18.890000   \n",
       "4          60  19.89  46.333333  19.2  44.530000  19.79  45.000000  18.890000   \n",
       "\n",
       "        RH_4         T5  ...    T8       RH_8         T9   RH_9     T_out  \\\n",
       "0  45.566667  17.166667  ...  18.2  48.900000  17.033333  45.53  6.600000   \n",
       "1  45.992500  17.166667  ...  18.2  48.863333  17.066667  45.56  6.483333   \n",
       "2  45.890000  17.166667  ...  18.2  48.730000  17.000000  45.50  6.366667   \n",
       "3  45.723333  17.166667  ...  18.1  48.590000  17.000000  45.40  6.250000   \n",
       "4  45.530000  17.200000  ...  18.1  48.590000  17.000000  45.40  6.133333   \n",
       "\n",
       "   Press_mm_hg  RH_out  Windspeed  Visibility  Tdewpoint  \n",
       "0        733.5    92.0   7.000000   63.000000        5.3  \n",
       "1        733.6    92.0   6.666667   59.166667        5.2  \n",
       "2        733.7    92.0   6.333333   55.333333        5.1  \n",
       "3        733.8    92.0   6.000000   51.500000        5.0  \n",
       "4        733.9    92.0   5.666667   47.666667        4.9  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 rows of the data using the .head method\n",
    "energy.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-champion",
   "metadata": {},
   "source": [
    "All of the features are already numeric, so we do not need to do any additional feature encoding. \n",
    "\n",
    "Now, separate the data into labels `y` with column `Appliances` and features `X` with the rest of the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "broadband-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index just the \"Appliances\" column into a new variable y\n",
    "y = energy[\"Appliances\"]\n",
    "X = energy.drop(\"Appliances\", axis=1)\n",
    "\n",
    "\n",
    "# Remove the \"Appliances column from the data using the .drop method and set the result as new variable X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-seating",
   "metadata": {},
   "source": [
    "Finally, standardize the examples in X using a `StandardScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "massive-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScalar object and use it to standardize X\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-sample",
   "metadata": {},
   "source": [
    "## Linear Regression & Learning Curves\n",
    "\n",
    "Now that our data is prepared, we will start by training a standard linear regression model using stochastic gradient descent. In Scikit-Learn, this corresponds to the `SGDRegressor` class for regression tasks (or `SGDClassifier` for classification tasks). If you look at the documentation for `SGDRegressor` you should now understand nearly all of the keyword arguments and be able to connect them to material from Chapter 4 in the textbook and class (even if the notation is different): https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html). \n",
    "\n",
    "As with most of the Scikit-Learn classes, its worth double-checking the default argument values before doing any training. In this case, we see that `SGDRegressor` uses mean-squared loss (as we did in class). It also uses a L2 penalty, meaning that by default, this class technically performs *Ridge Regression* rather than vanilla linear regression. You can change the loss function to `none`, `l1`, or `elasticnet` to perform Linear Regression, Lasso Regression, or Elastic Net. Note that the `SGDRegressor` class is different from the `LinearRegression`, `Ridge` or `Lasso` classes in that `LinearRegression`, `Ridge` and `Lasso` attempt to solve the closed-form solution of the training minimization problem, while `SGDRegressor` performs stochastic gradient descent. \n",
    "\n",
    "Before we get fancy, let's try it the easy way by creating a default instance of the `SGDRegressor` class and using the `cross_val_score()` function to train and test performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "competent-involvement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAE:  58.20794473593484\n"
     ]
    }
   ],
   "source": [
    "# Create a SGDRegressor object\n",
    "sgd = sklearn.linear_model.SGDRegressor()\n",
    "\n",
    "# Use the cross_val_score function to perform 5-fold cross validation. Use negative mean absolute error as the performance metric (keyword argument \"scoring\")\n",
    "# Negative mean abs error: the negative of the abs value of the sum of differences between predicted and actual labels \n",
    "scores = sklearn.model_selection.cross_val_score(sgd, X, y, cv=5, scoring=\"neg_mean_absolute_error\")\n",
    "# print the average score\n",
    "print(\"Average MAE: \", -np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-contents",
   "metadata": {},
   "source": [
    "**DISCUSSION:** Do you think this is good or bad? Look at the range of Watt-hours in the actual labels `y` to see whether or not this error represents a significant portion of the label range.\n",
    "\n",
    "When you have a performing model that performs questionably well, it helps to make as many visualizations as you can to understand what's going wrong. We will start by plotting a learning curve over the size of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hidden-profile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 5100 5200 5300 5400 5500 5600 5700 5800 5900 6000 6100 6200 6300 6400 6500 6600 6700 6800 6900 7000 7100 7200 7300 7400 7500 7600 7700 7800 7900 8000 8100 8200 8300 8400 8500 8600 8700 8800 8900 9000 9100 9200 9300 9400 9500 9600 9700 9800 9900 10000 10100 10200 10300 10400 10500 10600 10700 10800 10900 11000 11100 11200 11300 11400 11500 11600 11700 11800 11900 12000 12100 12200 12300 12400 12500 12600 12700 12800 12900 13000 13100 13200 13300 13400 13500 13600 13700 13800 13900 14000 14100 14200 14300 14400 14500 14600 14700 14800 14900 15000 15100 15200 15300 15400 15500 15600 15700 15800 15900 16000 16100 16200 16300 16400 16500 16600 16700 16800 16900 17000 17100 17200 17300 17400 17500 17600 17700 17800 17900 18000 18100 18200 18300 18400 18500 18600 18700 18800 18900 19000 19100 19200 19300 19400 19500 19600 19700 "
     ]
    }
   ],
   "source": [
    "# Create a list with the number of examples you will use for training, ranging from 100 to the full training set in steps of 100\n",
    "n_examples = range(100, X.shape[0], 100)\n",
    "\n",
    "# Create two lists to hold 1) the training errors and 2) the validation error\n",
    "train_errors = []\n",
    "val_errors = []\n",
    "\n",
    "\n",
    "# Loop over each number of examples n\n",
    "for n in n_examples :\n",
    "    \n",
    "    # Select the first n training examples and training labels \n",
    "    print(n, end=' ')\n",
    "    X_curr = X[0:n, :]\n",
    "    y_curr = y[0:n]\n",
    "    # Create a SGDRegressor object\n",
    "    SGD = sklearn.linear_model.SGDRegressor\n",
    "\n",
    "    # Use the cross_validate function (NOT cross_val_score) to perform 5-fold cross-validation and return the \n",
    "    #     negative mean absolute error on both the training and the validation set. Look this function up in the docs for details!\n",
    "    scores = sklearn.model_selection.cross_validate(sgd, X, y, cv=5, scoring=\"neg_mean_absolute_error\", return_train_score=True)\n",
    "    \n",
    "    # Compute the average training and validation scores accross all folds\n",
    "    avg_train_score = -scores[\"train_score\"].mean()\n",
    "    avg_val_score = -scores[\"test_score\"].mean()\n",
    "    \n",
    "    # Append the average scores into the accumulator lists\n",
    "    train_errors.append(avg_train_score)\n",
    "    val_errors.append(avg_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "consolidated-escape",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.plot(*args, scalex=True, scaley=True, data=None, **kwargs)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Matplotlib to plot the training and validation errors (y-axis) against the number of training examples (x-axis)\n",
    "plt.plot\n",
    "\n",
    "# add a x-axis label and a y-axis label\n",
    "\n",
    "\n",
    "# add a legend and grid lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-surfing",
   "metadata": {},
   "source": [
    "This looks like a fairly typical learning curve. The error goes up initially as you get more than a few datapoints, but then back down as the model learns to generalize.\n",
    "\n",
    "**DISCUSSION:** Look at the vertical space between the validation error and the training error at the end of the curve. Do you think that this is an example of *overfitting* or *underfitting*?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-warehouse",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors\n",
    "\n",
    "Now that we have tried out linear regression, let's see whether a nearest neighbors regressor does better or worse on this dataset. \n",
    "\n",
    "**DISCUSSION:** What are two reasons why this dataset might be more amenable to KNN than linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "divine-absorption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAE:  71.90787940207751\n"
     ]
    }
   ],
   "source": [
    "# Create a KNeighborsRegressor object to perform 3-nearest neighbors\n",
    "\n",
    "knn = sklearn.neighbors.KNeighborsRegressor(n_neighbors=5)\n",
    "# train and evaluate using the cross_val_score function and the negative mean absolute error metric\n",
    "scores = sklearn.model_selection.cross_val_score(knn, X, y, cv=5, scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "# print the average score\n",
    "print(\"Average MAE: \", -np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-sociology",
   "metadata": {},
   "source": [
    "The primary hyperparameter for KNN is the number of neighbors. When training a model with just a few hyperparameters, a good strategy is often to just try a reasonable range of values (e.g. 1-10) and see which value gives the highest cross validation score. In the following cell, write a loop that creates and trains a KNNRegressor on the energy dataset for a range of values of `n_neighors` and decides which value is the best choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "official-bundle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 "
     ]
    }
   ],
   "source": [
    "# Create list to store average scores\n",
    "avg_score = []\n",
    "\n",
    "# Loop over neighbors n = 1 to 10\n",
    "for n in range(1, 11):\n",
    "    print(n, end= \" \")\n",
    "    \n",
    "    # Create a KNNRegressor object for the current number of neighbors\n",
    "    knn = sklearn.neighbors.KNeighborsRegressor(n_neighbors=5)\n",
    "    # train and evaluate using the cross_val_score function and the negative mean absolute error metric\n",
    "    scores = sklearn.model_selection.cross_val_score(knn, X, y, cv=5, scoring=\"neg_mean_absolute_error\")\n",
    "    # store the average score\n",
    "    avg_score.append(-np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab632aa-97a0-41ba-b9f9-0052004fa1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the average scores against the number of neighbors\n",
    "\n",
    "\n",
    "# Add axis labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-toolbox",
   "metadata": {},
   "source": [
    "Finally, create a learning curve for the KNN model and your choice of `n_neighbors`. You can copy and paste code from the `SGDRegressor` learning curve above. Note that KNNs take longer to perform predictions the larger the training dataset, so you may want to reduce the number of iterations to speed up your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with the number of examples you will use for training, ranging from 100 to the full training set in steps of 1000\n",
    "\n",
    "\n",
    "# Create two lists to hold 1) the training errors and 2) the validation error\n",
    "\n",
    "\n",
    "# Loop over each number of examples n\n",
    "\n",
    "    \n",
    "    # Select the first n training examples and training labels \n",
    "\n",
    "    \n",
    "    # Create a KNeighborsRegressor object\n",
    "\n",
    "\n",
    "    # Use the cross_validate function (NOT cross_val_scores) to perform 5-fold cross-validation and return the \n",
    "    #     negative mean absolute error on both the training and the validation set. Look this function up in the docs for details!\n",
    "    \n",
    "    \n",
    "    # Compute the average training and validation scores accross all folds\n",
    "\n",
    "    \n",
    "    # Append the average scores into the accumulator lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Matplotlib to plot the training and validation errors (y-axis) against the number of training examples (x-axis)\n",
    "\n",
    "\n",
    "# add a x-axis label and a y-axis label\n",
    "\n",
    "\n",
    "# add a legend and grid lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-legend",
   "metadata": {},
   "source": [
    "**DISCUSSION:** Look at the vertical space between the validation error and the training error at the end of the curve. Do you think that this is an example of *overfitting* or *underfitting*?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-empire",
   "metadata": {},
   "source": [
    "## *(Optional)* Regularization & Hyperparameters for Linear Regression\n",
    "\n",
    "The `SGDRegressor` class has many constructor keyword arguments that change the behavior of the model. Let's see how modifying these parameters affects model performance. Perform the following tasks in the cells below:\n",
    "1. Choose an argument to `SGDRegressor` that you think will impact performance accuracy\n",
    "2. Try multiple (at least 3) different options for this argument and use `cross_val_score()` to test the performance of the model with each of these options.\n",
    "3. Plot a bar chart comparing model performance for each of the argument options\n",
    "\n",
    "**DISCUSSION:** Once you have finished the tasks above, discuss whether the options you chose made a substantial difference in performance and why you think this might be the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27937510-3391-4da1-a85f-3a3211b2cd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
