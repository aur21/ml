{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "devoted-blake",
   "metadata": {},
   "source": [
    "# Keras Functional Model & Reducing Overfitting: Programming Practice\n",
    "\n",
    "COSC 410: Applied Machine Learning\\\n",
    "Colgate University\\\n",
    "*Prof. Apthorpe*\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook will give you practice with the following topics:\n",
    "  1. Creating and training FNNs using the Keras Functional Model\n",
    "  2. Using early stopping, regularization, and dropout to reduce overfitting\n",
    "\n",
    "We will be using the CIFAR-10 dataset. The description of the dataset is here: https://www.cs.toronto.edu/%7Ekriz/cifar.html\n",
    "\n",
    "## Part 1. Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "np.random.seed(0) # set random seeds so everyone gets same results\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b67a3da-c02b-4101-990c-b704c52e0a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 data\n",
    "cifar10 = ks.datasets.cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "# Create a list with the class names\n",
    "class_names = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-trash",
   "metadata": {},
   "source": [
    "We should check the shape of the data and balance of the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-there",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataframe shapes\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "print(len(train_labels))\n",
    "print(len(test_labels))\n",
    "\n",
    "# Print distribution classes in training and test data\n",
    "print(np.unique(train_labels, return_counts=True)[1])\n",
    "print(np.unique(test_labels, return_counts=True)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-action",
   "metadata": {},
   "source": [
    "## Part 2. Creating a FNN using the Functional Model\n",
    "\n",
    "The Keras **Functional API** allows you to create neural networks more complicated than possible using the `Sequential` class. The documentation for the Functional API is here: https://keras.io/guides/functional_api/.\n",
    "\n",
    "Like the `Sequential` class, the Functional API requires that you create layer objects representating the elements of your neural network (e.g. `Layers.Dense`). Although we didn't see this when using `Sequential`, these layer objects can be used as functions to build a network by passing earlier layers as arguments of successive layers.\n",
    "\n",
    "### Part 2.1. Creating Layers and Specifying Architecture\n",
    "\n",
    "We will create a \"wide and deep\" network with one \"deep\" path through several hidden layers and one \"wide\" path from the input directly to the output layer.\n",
    "\n",
    "Networks created with the Functional API start with one (or more) `Input` layers that specify the size of the data: https://keras.io/api/layers/core_layers/input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input layer\n",
    "input_layer = ks.layers.Input(shape=[32, 32, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-weight",
   "metadata": {},
   "source": [
    "We next create the flatten layer and the batch normalization layer, using function calls to indicate how information flows through the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Flatten layer that gets input from the Input layer\n",
    "flatten_layer = ks.layers.Flatten()(input_layer)\n",
    "\n",
    "# Create a Batch Normalization layer that gets input from the Flatten layer\n",
    "norm_layer = ks.layers.BatchNormalization()(flatten_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-stations",
   "metadata": {},
   "source": [
    "We then create the hidden layers for the \"deep\" path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create three hidden layers with ReLU activation functions\n",
    "h1 = ks.layers.Dense(128, activation=\"relu\")(norm_layer)\n",
    "h2 = ks.layers.Dense(64, activation=\"relu\")(h1)\n",
    "h3 = ks.layers.Dense(32, activation=\"relu\")(h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a84588e-5bf4-44b0-a283-4a28ab4606db",
   "metadata": {},
   "source": [
    "Then we create the \"wide\" part of the network, which takes the flattened normalized input and directly concatenates it with the output of the deep part of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc37f09-4bcd-420a-a8c5-ed50349952e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Concatenate layer that combines the output of h3 with flattened normalized input\n",
    "concat_layer = ks.layers.Concatenate()([norm_layer, h3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-disease",
   "metadata": {},
   "source": [
    "Finally, we add the single output layer that produces the class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output layer with softmax activation function\n",
    "output_layer = ks.layers.Dense(10, activation=\"softmax\")(concat_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-emission",
   "metadata": {},
   "source": [
    "### Part 2.2. Creating, compiling, and training the model \n",
    "\n",
    "After creating the layers and specifying the architecture using function calls, we create the `Model` object. \n",
    "\n",
    "We need to specify the input(s) and output(s) of the model when we create the object. The rest of the architecture is already set from the function calls when the layers were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model using the layers from above\n",
    "model = ks.Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-sending",
   "metadata": {},
   "source": [
    "Once the `Model` object is created, we can examine it using `.summary()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2abf3bc-d9bb-4710-b450-3634af52d3f9",
   "metadata": {},
   "source": [
    "It can also be helpful to print the arrow graph of more complicated networks using `plot_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf8297-9dda-4399-9d00-86809505c25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot network - This requires pydot and GraphViz\n",
    "ks.utils.plot_model(model, show_shapes=True, show_dtype=False, show_layer_names=True, rankdir=\"TB\", expand_nested=False, dpi=96)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-refrigerator",
   "metadata": {},
   "source": [
    "We also need to `.compile()` the model the same way as we would using the Sequential API. All of the possible arguments to `.compile()` that we saw in class last week are still available when using the Functional API (e.g. the `optimizer`, `loss`, and `metrics` keyword arguments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-generic",
   "metadata": {},
   "source": [
    "**Discussion:** Why did we choose *sparse categorical crossentropy* as our loss function? Why didn't we choose *categorical crossentropy*?\n",
    "\n",
    "Finally, we train the model using the `.fit()` method. Again, the required and optional arguments to `.fit()` are the same as if the model were created with the Sequential API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=100, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e170835a-075c-4b46-8756-5dd77cc25fa5",
   "metadata": {},
   "source": [
    "## Part 3. Reducing Overfitting\n",
    "\n",
    "### Part 3.1. Baseline Model\n",
    "\n",
    "First, we'll create a simple FNN with 3 hidden layers and no overfitting prevention using the Sequential model. \n",
    "\n",
    "**Note:** Instead of using `.add()`, we will pass all the layers directly to the `Sequential` constructor as a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3557ff3-edcc-4aa4-b042-c6343e31d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ks.models.Sequential([\n",
    "    ks.layers.Flatten(input_shape=[32, 32, 3]),\n",
    "    ks.layers.BatchNormalization(),\n",
    "    ks.layers.Dense(128, activation=\"relu\"),\n",
    "    ks.layers.Dense(64, activation=\"relu\"),\n",
    "    ks.layers.Dense(32, activation=\"relu\"),\n",
    "    ks.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels, batch_size=100, epochs=10, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a401eed2-1fa9-49f0-97b6-2caee4f67f1d",
   "metadata": {},
   "source": [
    "### Part 3.2. Activation Functions & Initializers\n",
    "\n",
    "Next, we'll try an ELU activation function and a He weight initialization instead of the ReLU activation and Glorot initialization we have been using. These hyperparameter options are recommended by the textbook, but like any hyperparameter setting, it's worth comparing performance experimentally.  Let's see if it makes a difference for the CIFAR-10 classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c792d02e-b69e-41c7-b893-275a8f74b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ks.models.Sequential([\n",
    "    ks.layers.Flatten(input_shape=[32, 32, 3]),\n",
    "    ks.layers.BatchNormalization(),\n",
    "    ks.layers.Dense(128, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    ks.layers.Dense(64, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    ks.layers.Dense(32, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    ks.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels, batch_size=100, epochs=10, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea38308-7bb4-4ef4-ad89-122b08d3d93e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Since the performance of the model is about the same, We'll stick with the original activation and initializer settings going forward. \n",
    "\n",
    "### Part 3.3. Early Stopping\n",
    "\n",
    "Thus far, we have been manually watching the training to see when the validation error plateaus. We can configure Keras to do this automatically using the `EarlyStopping` class (documentation here: https://keras.io/api/callbacks/early_stopping/). We specify \n",
    "\n",
    "1. We want the early stopping to be based on the validation loss `\"val_loss\"`\n",
    "2. We want training to stop when the validation loss has not improved (`min_delta=0`) for 5 epochs (`patience=5`)\n",
    "3. We want the model to be \"rolled back\" to the end of the epoch with the best validation performance (`restore_best_weights=True`)\n",
    "\n",
    "The `EarlyStopping` object gets passed to the model as a callback in `.fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e88cb84-8f0e-4779-b5b1-328c3c42c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ks.models.Sequential([\n",
    "    ks.layers.Flatten(input_shape=[32, 32, 3]),\n",
    "    ks.layers.BatchNormalization(),\n",
    "    ks.layers.Dense(128, activation=\"relu\"),\n",
    "    ks.layers.Dense(64, activation=\"relu\"),\n",
    "    ks.layers.Dense(32, activation=\"relu\"),\n",
    "    ks.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_callback = ks.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(train_images, train_labels, batch_size=100, epochs=100, validation_split=0.15, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c32a7ad-e08d-4857-a7f9-18b06263726d",
   "metadata": {},
   "source": [
    "### Part 3.4. Regularization\n",
    "\n",
    "Next, we'll try using L1 regularization via the `kernel_regularizer` keyword argument of our `Dense` layers. The documentation for all regularizer options provided by Keras is here: https://keras.io/api/layers/regularizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c2662-5b82-4923-b3d4-d411806b3bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ks.models.Sequential([\n",
    "    ks.layers.Flatten(input_shape=[32, 32, 3]),\n",
    "    ks.layers.BatchNormalization(),\n",
    "    ks.layers.Dense(128, activation=\"relu\", kernel_regularizer=ks.regularizers.l1(0.001)),\n",
    "    ks.layers.Dense(64, activation=\"relu\", kernel_regularizer=ks.regularizers.l1(0.001)),\n",
    "    ks.layers.Dense(32, activation=\"relu\", kernel_regularizer=ks.regularizers.l1(0.001)),\n",
    "    ks.layers.Dense(10, activation=\"softmax\", kernel_regularizer=ks.regularizers.l1(0.001))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels, batch_size=100, epochs=15, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388d2660-188a-454d-b09e-b2e8e553d7ab",
   "metadata": {},
   "source": [
    "### Part 3.5. Dropout\n",
    "\n",
    "We apply dropout by adding Dropout layers that specify the dropout rate (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a273258a-ba06-49a6-87d8-010ce5f4ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ks.models.Sequential([\n",
    "    ks.layers.Flatten(input_shape=[32, 32, 3]),\n",
    "    ks.layers.BatchNormalization(),\n",
    "    ks.layers.Dropout(rate=0.1),\n",
    "    ks.layers.Dense(128, activation=\"relu\"),\n",
    "    ks.layers.Dropout(rate=0.1),\n",
    "    ks.layers.Dense(64, activation=\"relu\"),\n",
    "    ks.layers.Dropout(rate=0.1),\n",
    "    ks.layers.Dense(32, activation=\"relu\"),\n",
    "    ks.layers.Dropout(rate=0.1),\n",
    "    ks.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels, batch_size=100, epochs=15, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bc3a30-dcfe-4f24-8e4a-c27841a0e100",
   "metadata": {},
   "source": [
    "## Part 7. Training Set Augmentation\n",
    "\n",
    "Tensorflow conveniently provides layers that perform training set augmentation on image data (https://www.tensorflow.org/guide/keras/preprocessing_layers#image_data_augmentation). We can add these directly to our model. By default, these layers are only active during *training* and deactivated during *prediction*, just as we want for training set augmentation. As always, be sure to check the documentation because each of these layers have other hyperparameters that you can adjust in the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d9f9be-fa41-4115-93b8-b59874a60b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  ks.layers.RandomFlip(\"horizontal\"), \n",
    "  ks.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "  #ks.layers.RandomRotation(0.1),  \n",
    "  #ks.layers.RandomZoom(height_factor=0.1, width_factor=0.1),\n",
    "  #ks.layers.RandomContrast(factor=0.1),\n",
    "])\n",
    "\n",
    "\n",
    "model = ks.models.Sequential([\n",
    "    data_augmentation,\n",
    "    ks.layers.Flatten(input_shape=[32, 32, 3]),\n",
    "    ks.layers.BatchNormalization(),\n",
    "    ks.layers.Dense(128, activation=\"relu\"),\n",
    "    ks.layers.Dense(64, activation=\"relu\"),\n",
    "    ks.layers.Dense(32, activation=\"relu\"),\n",
    "    ks.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# The data augmentation layers require examples of type float32 instead of CIFAR-10's default uint8, so we typecast before training \n",
    "train_images = tf.cast(train_images, dtype=tf.float32)\n",
    "\n",
    "model.fit(train_images, train_labels, batch_size=100, epochs=15, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a16bbf-0d4b-4052-b0b5-df4e868d2fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
